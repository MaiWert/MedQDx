#  MedQDx: Diagnose Like a Doctor 

MedQDx is a cutting-edge benchmark that simulates realistic, partial clinical scenarios to evaluate large language models’ diagnostic strategies in reaching a diagnosis through adaptive, question-driven reasoning.

![image](https://github.com/user-attachments/assets/a4278d45-781e-4022-9c2f-cf50c0549947)

##  MedQDx Data
### Raw Data - [Symptom‑Disease Prediction Dataset (SDPD)](https://data.mendeley.com/datasets/dv5z3v2xyd/1).

The Symptom-Disease Prediction Dataset (SDPD) is a comprehensive collection of structured data linking symptoms to various diseases, meticulously curated to facilitate research and development in predictive healthcare analytics. This dataset provides a comprehensive collection of disease names and associated symptoms, encoded in a one-hot manner.
* Size: 4961 rows | 132 symptoms | 41 unique diseases

Each row in the dataset represents one disease case:
* The "prognosis" column contains the disease name and the remaining columns represents a specific symptom.
* Each symptom column holds a value of 1 (symptom present) or 0 (symptom absent).

### Generated patient cases
Patient cases generated by GPT 4o mini based on Symptom‑Disease Prediction Dataset
| Column          | Column Description                      |
|----------------|------------------------------|
| `prognosis`    | Disease name |
| `symptoms`    | The associated symptoms with the disease case |
| `100% Case` | Patient case with all symptoms associated with the disease case      |
| `80% Case`  | The patient case with approximately 80% of the symptoms      |
| `50% Case`   | The patient case with approximately 50% of the symptoms         |


### MedQDx Benchmark
Diagnostic cases across three rounds, detailing each round’s questions, answers, diagnoses, and similarity scores.
| Column          | Column Description                      |
|----------------|------------------------------|
| `prognosis`    | Disease name |
| `symptoms`    | The associated symptoms with the disease case |
| `100% Case` | Patient case with all symptoms associated with the disease case      |
| `80% Case`  | The patient case with approximately 80% of the symptoms      |
| `50% Case`   | The patient case with approximately 50% of the symptoms         |
| `Question_1` | The doctor’s first diagnostic question given the 50% case      |
| `Answer_1`  | The patient’s answer to Question_1      |
| `Diagnosis_1`   | The doctor’s first diagnosis (after Answer_1)         |
| `Similarity_1`   | Cosine similarity between Diagnosis_1 and the prognosis (ground-truth disease)        |
| `Question_2` | The doctor’s second diagnostic question given the 50% case and conversation history   |
| `Answer_2`  | The patient’s answer to Question_2      |
| `Diagnosis_2`   | The doctor’s second diagnosis (after Answer_2)         |
| `Similarity_2`   | Cosine similarity between Diagnosis_2 and the prognosis (ground-truth disease)        |
| `Question_3` | The doctor’s third  diagnostic question given the 50% case and conversation history   |
| `Answer_3`  | The patient’s answer to Question_3      |
| `Diagnosis_3`   | The doctor’s third diagnosis (after Answer_3)         |
| `Similarity_3`   | Cosine similarity between Diagnosis_3 and the prognosis (ground-truth disease)        |



##  Table of Contents

1. [ Introduction](#introduction)
2. [ Project Structure](#project-structure)
3. [ Submodule Overviews](#submodule-overviews)

   * [ EDA & Baseline](#eda--baseline)
   * [ Benchmark Creation](#benchmark-creation)
   * [ Benchmark Evaluation](#benchmark-evaluation)
4. [ Getting Started](#getting-started)
5. [ Presentation](#presentation)




##  Introduction
Patients rarely present a complete clinical picture at first, so physicians must engage in dynamic, targeted questioning to uncover critical details. The ability to conduct an adaptive dialogue—asking the right follow-up questions at each step—is therefore essential for high-quality diagnostic reasoning and treatment planning.

Large language models (LLMs) have demonstrated impressive capabilities in medical natural language understanding and generation, and are increasingly being integrated as diagnostic support tools in clinical workflows. However, existing benchmarks typically evaluate LLMs on fully revealed patient cases, without measuring their capacity for conducting strategic inquiry under partial clinical picture.

**MedQDx** addresses this gap by simulating realistic diagnostic uncertainty through an interactive, multi-round question-and-answer format. In MedQDx, an LLM “doctor” must iteratively question an LLM “patient” using only partial case information (50% of the data) and make a diagnosis after each round. This benchmark enables robust evaluation of an LLM’s ability to adapt its questioning strategy, refine its hypotheses, and ultimately align its predictions with the ground-truth diagnosis.  

By requiring multi-turn doctor–patient interactions, we push AI from passive responders to active clinical reasoning partners.


*  **Zero-Shot Diagnostic Accuracy (ZDA)**
*  **Mean Question-based Diagnostic Similarity (MQD)**
*  *  **Mean of Max Similarity Across Row (MMS)**

##  Project Structure

```bash
MedQDx/                                  
├── EDA and Baseline/                     
│   ├── 📄 EDA & Baseline README.md
│   ├──  MedQDx__EDA_and_Baseline.ipynb
│   └──  Patient cases.csv
├── Benchmark Creation/                   
│   ├── 📄 Benchmark Creation README.md
│   ├──  MedQDx_Benchmark_Creation.ipynb
│   └──  MedQDx_Benchmark.csv
├── Benchmark Evaluation/                          
│   ├── 📄 Evaluation README.md
│   └──  MedQDx_Evaluation.ipynb
├── Presentations/
│   ├──  MedQDx - Final Presentation.pdf
│   ├──  MedQDx - Interim Presentation.pdf
│   └──  MedQDx - Project proposal.pdf
└── 📘 README.md                           # ← You are here!
```


##  Submodule Overviews

###  EDA & Baseline

Dive into the Symptom–Disease Prediction Dataset (SDPD) with cleaning, exploratory analysis, and baseline patient case generation. Covers 100%, 80%, and 50% symptom reveals with Jaccard analysis.

> 🔗 [Explore](./EDA%20and%20Baseline/EDA%20%26%20Baseline%20README.md)

###  Benchmark Creation

Simulate doctor–patient dialogues using different LLM personas. Collect questions, answers, and diagnoses for each partial case and export detailed conversation logs.

> 🔗 [Simulate](./Benchmark%20Creation/Benchmark%20Creation%20README.md)

###  Benchmark Evaluation

Assess the AI diagnostician’s performance by calculating ZDA, similarity metrics, and visualizing results across symptom completeness tiers.

> 🔗 [Evaluate](./Evaluation/Evaluation%20README.md)


---

##  Getting Started

1. **Clone the repository**

   ```bash
   git clone https://github.com/MaiWert/MedQDx.git
   cd MedQDx
   ```
2. **Install dependencies**

   ```bash
   pip install -r requirements.txt
   ```
3. **Configure credentials**

   ```bash
   export MedQDx_ENDPOINT="https://<your-azure-endpoint>"
   export MedQDx_API_KEY="<your-api-key>"
   export MedQDx_API_VERSION="2024-12-01-preview"
   ```
4. **Launch notebooks**

   *  `EDA & Baseline/MedQDx__EDA_and_Baseline.ipynb`
   *  `Benchmark Creation/MedQDx_Benchmark_Creation.ipynb`
   *  `Evaluation/MedQDx_Evaluation.ipynb`



*✨ MedQDx © 2025 Mai Werthaim & Maya Kimhi*
